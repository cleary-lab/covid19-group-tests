group_by(destination_country,origin_city)%>%
summarise(export_risk=sum(prev_vol_product))
scaling_factor
exp(scaling_factor)
head(prev_flight_all_cities_FINAL_2)
risk_all_cities
risk_all_cities<-prev_flight_all_cities_FINAL_2%>%
mutate(prev_vol_product=((daily_prevalence*daily_volume)))
risk_all_cities<-prev_flight_all_cities_FINAL_2%>%
mutate(prev_vol_product=((daily_prevalence*daily_volume)))
risk_all_cities
ggplot(risk_all_cities) + geom_line(aes(x=date,y=prev_vol_product))
ggplot(risk_all_cities) + geom_line(aes(x=date,y=prev_vol_product)) + facet_grid(origin_city~destination_country)
ggplot(risk_all_cities) + geom_line(aes(x=date,y=cumsum(prev_vol_product))) + facet_grid(origin_city~destination_country)
risk_all_cities<-prev_flight_all_cities_FINAL_2%>%
mutate(prev_vol_product=((daily_prevalence*daily_volume)))%>%
group_by(destination_country,origin_city)%>%
summarise(export_risk=sum(prev_vol_product))%>%
mutate(risk_importation=exp(scaling_factor)*export_risk)%>%
group_by(destination_country)%>%
summarise(num_exp_dest=sum(risk_importation))
risk_all_cities
risk_all_cities<-prev_flight_all_cities_FINAL_2%>%
mutate(prev_vol_product=((daily_prevalence*daily_volume)))%>%
group_by(destination_country,origin_city)%>%
summarise(export_risk=sum(prev_vol_product))
risk_all_cities
- read_csv("~/Downloads/prev_flight_all_cities_FINAL_2.csv")
risk_all_cities<-prev_flight_all_cities_FINAL_2%>%
mutate(prev_vol_product=((daily_prevalence*daily_volume)))
ggplot(risk_all_cities) + geom_line(aes(x=date,y=cumsum(prev_vol_product))) + facet_grid(origin_city~destination_country)
risk_all_cities %>% filter(origin_city == "Beijing" & destination_country == "Egpyt")
risk_all_cities %>% filter(origin_city == "Beijing" & destination_country == "Egypt")
risk_all_cities %>% filter(origin_city == "Beijing" & destination_country == "Egypt") %>% pull(prev_vol_product)
risk_all_cities %>% filter(origin_city == "Beijing" & destination_country == "Egypt") %>% pull(prev_vol_product) %>% sum
risk_all_cities %>% filter(origin_city == "Beijing" & destination_country == "Egypt") %>% pull(prev_vol_product) %>% cumsum
2000/2000000
2000/2000000*100
2000/200000*100
install.packages("lognorm")
library(lognorm)
getLognormMode(1.57,0.65)
plot(dlnorm(0:30,1.57, 0.65))
mean(rlnorm(1000,1.57,0.65))
sd(rlnorm(1000,1.57,0.65))
x <- (rlnorm(1000,1.57,0.65))
dens(density(x))
dens <- density(x)
dens$x[which.max(dens$y)]
exp(1.57 - 0.67^2)
exp(1.57 - 0.65^2)
library(lazymcmc)
run_MCMC
devtools::install_github("jameshay218/lazymcmc",ref="parallel_tempering")
devtools::install_github("jameshay218/lazymcmc",ref="parallel_tempering")
devtools::install_github("jameshay218/lazymcmc",ref="parallel_tempering",force=TRUE)
library(lazymcmc)
run_MCMC
#devtools::install_github("jameshay218/lazymcmc",ref="parallel_tempering")
#library(lazymcmc)
devtool::load_all("~/Documents/GitHub/lazymcmc/")
#devtools::install_github("jameshay218/lazymcmc",ref="parallel_tempering")
#library(lazymcmc)
devtools::load_all("~/Documents/GitHub/lazymcmc/")
run_MCMC
hist(rgamma(1000, 5, rate=5/0.01))
hist(rgamma(1000, 5, rate=5/0.001))
hist(rnorm(1000, 4.5, 1))
hist(rnorm(10000, 2.5,1))
hist(rnorm(10000, 2.5,0.5))
hist(rnorm(10000, 1/4.5,1))
hist(1/rnorm(10000, 1/4.5,1))
rnorm(10000, 1/4.5,1)
1/rnorm(10000, 1/4.5,1)
hist(1/rnorm(10000, 1/4.5,1))
hist(1/rnorm(10000, 1/4.5,1),xlim=c(0,100))
hist(rgamma(1000,shape=5,rate=5/0.001))
hist(rgamma(1000,shape=5,rate=50/0.001))
gamma_pars_from_mean_sd(0.01,0.1)
gamma_pars_from_mean_sd <- function(gamma_mean, gamma_var){
scale <- gamma_var/gamma_mean
shape <- gamma_mean/scale
return(list("shape"=shape,"scale"=scale))
}
gamma_pars_from_mean_sd(0.01,0.1)
hist(rgamma(1000,shape=0.001, scale=10))
gamma_pars_from_mean_sd(0.01,0.01)
hist(rgamma(1000,shape=0.001, scale=10))
hist(rgamma(1000,shape=0.01, scale=1))
gamma_pars_from_mean_sd(0.01,0.001)
hist(rgamma(1000,shape=0.01, scale=1))
gamma_pars_from_mean_sd(0.1,0.001)
hist(rgamma(1000,shape=0.01, scale=1))
gamma_pars_from_mean_sd(1,0.001)
hist(rgamma(1000,shape=0.01, scale=1))
gamma_pars_from_mean_sd(0.01,0.0001)
hist(rgamma(1000,shape=0.01, scale=1))
g_pars <- gamma_pars_from_mean_sd(0.01,0.0001)
hist(rgamma(1000,shape=g_pars[[1]], scale=g_pars[[2]]))
g_pars <- gamma_pars_from_mean_sd(0.01,0.001)
hist(rgamma(1000,shape=g_pars[[1]], scale=g_pars[[2]]))
hist(rgamma(1000,shape=g_pars[[1]], scale=g_pars[[2]]),breaks=100)
hist(rnorm(10000, 2.5,0.5))
hist(rnorm(10000, 1/4.5,1))
gamma_pars_from_mean_sd <- function(gamma_mean, gamma_var){
scale <- gamma_var/gamma_mean
shape <- gamma_mean/scale
return(list("shape"=shape,"scale"=scale))
}
g_pars <- gamma_pars_from_mean_sd(0.01,0.001)
hist(rgamma(1000,shape=g_pars[[1]], scale=g_pars[[2]]),breaks=100)
chain <- read.csv("SIR_fitting_multivariate_chain.csv")
plot(coda::as.mcmc(chain))
hist(1/chain$sigma)
plot(coda::as.mcmc(chain))
chain <- read.csv("SIR_fitting_multivariate_chain.csv")
plot(coda::as.mcmc(chain[chain$sampno > 10000,]))
plot(chain$R0 ~ chain$sigma)
plot(chain$rho ~ chain$sigma)
chain <- read.csv("SIR_fitting_multivariate_chain.csv")
chain <- chain[chain$sampno > 10000,]
plot(chain$rho ~ chain$sigma)
chain <- read.csv("SIR_fitting_univariate_chain.csv")
plot(coda::as.mcmc(chain))
chain <- read.csv("SIR_fitting_univariate_chain.csv")
plot(coda::as.mcmc(chain))
chain <- read.csv("SIR_fitting_univariate_chain.csv")
plot(coda::as.mcmc(chain))
plot(chain$R0~chain$sigma
)
plot(chain$R0~chain$rho)
plot(chain$sigma~chain$rho)
1/0.15
chain <- read.csv("SIR_fitting_base_univariate_chain.csv")
plot(coda::as.mcmc(chain))
chain <- read.csv("SIR_fitting_base_univariate_chain.csv")
plot(coda::as.mcmc(chain[chain$sampno > 10000,]))
chain <- read.csv("SIR_fitting_multivariate_chain.csv")
plot(coda::as.mcmc(chain[chain$sampno > 1000,]))
plot(coda::as.mcmc(chain[chain$sampno > 1000,]))
chain <- read.csv("SIR_fitting_multivariate_chain.csv")
plot(coda::as.mcmc(chain[chain$sampno > 1000,]))
chain <- read.csv("SIR_fitting_multivariate_chain.csv")
plot(coda::as.mcmc(chain[chain$sampno > 1000,]))
chain <- read.csv("SIR_fitting_multivariate_chain.csv")
plot(coda::as.mcmc(chain[chain$sampno > 1000,]))
chain <- read.csv("SIR_fitting_base_multivariate_chain.csv")
plot(coda::as.mcmc(chain[chain$sampno > 1000,]))
1/0.3
plot(coda::as.mcmc(chain[chain$sampno > 1000,]))
plot(coda::as.mcmc(chain[chain$sampno > 1000,]))
chain <- read.csv("SIR_fitting_multivariate_chain.csv")
plot(coda::as.mcmc(chain[chain$sampno > 1000,]))
chain <- read.csv("SIR_fitting_multivariate_chain.csv")
plot(coda::as.mcmc(chain[chain$sampno > 1000,]))
hist(rnorm(1000,0.05,1))
chain <- read.csv("SIR_fitting_multivariate_chain.csv")
plot(coda::as.mcmc(chain[chain$sampno > 1000,]))
library(tidyverse)
library(ggplot2)
## devtools::install_github("jameshay218/lazymcmc")
library(lazymcmc)
source("simulation_functions.R")
source("model_funcs.R")
## Entire popuation size (this is MA in 2018 from US Census Bureau)
population_n <- 6900000
setwd("~/Documents/GitHub/covid19-group-tests/code/viral_kinetics")
source("simulation_functions.R")
source("model_funcs.R")
## Entire popuation size (this is MA in 2018 from US Census Bureau)
population_n <- 6900000
## Sample size
n <- 1000000
## Epidemic growth rate
growth_rate <- 0.1
## Duration of epidemic so far in days
times <- 0:100
## Viral kinetics pars
## Change wd to local path
parTab <- read.csv("partab.csv",stringsAsFactors=FALSE)
chains <- load_mcmc_chains("~/Google Drive/nCoV/pool_samples/chains", parTab, FALSE, 1, burnin=200000,multi=TRUE)
chain <- as.data.frame(chains[[2]])
pars <- list(viral_peak_mean=mean(chain$viral_peak_mean), viral_peak_sd=mean(chain$viral_peak_sd),
wane_mean=mean(chain$wane_mean), wane_sd=mean(chain$wane_sd),
tp_last_day=7)
## Simulate the epidemic process
epidemic_process <- simulate_epidemic_process(population_n,0.1,times)
epidemic_process$plot
## Simulate infection times
infection_times <- simulate_infection_times(n, epidemic_process$overall_prob_infection, epidemic_process$incidence)
## Simulate symptom onset times using default incubation period distribution
onset_times <- simulate_symptom_onsets(infection_times)
## Simulate viral loads for the sample population
viral_loads <- simulate_viral_loads(infection_times, onset_times, times, pars)
## Have a look to see the window of detection for each simulated individual
viral_loads_bin <- apply(viral_loads, 1, function(x) x >= 2)
image(viral_loads_bin)
source('~/Documents/GitHub/covid19-group-tests/code/viral_kinetics/simulate_data.R', echo=TRUE)
setwd("~/Documents/GitHub/covid19-group-tests/code/viral_kinetics")
source('~/Documents/GitHub/covid19-group-tests/code/viral_kinetics/simulate_data.R', echo=TRUE)
getwd()
list.files()
source('~/Documents/GitHub/covid19-group-tests/code/viral_kinetics/simulate_data.R', echo=TRUE)
source('~/Documents/GitHub/covid19-group-tests/code/viral_kinetics/simulation_functions.R', echo=TRUE)
## Have a look to see the window of detection for each simulated individual
viral_loads_bin <- apply(viral_loads, 1, function(x) x >= 2)
## Simulate viral loads for the sample population
viral_loads <- simulate_viral_loads(infection_times, onset_times, times, pars)
source('~/Documents/GitHub/covid19-group-tests/code/viral_kinetics/simulation_functions.R', echo=TRUE)
## Simulate viral loads for the sample population
viral_loads <- simulate_viral_loads(infection_times, onset_times, times, pars)
source('~/Documents/GitHub/covid19-group-tests/code/viral_kinetics/simulation_functions.R', echo=TRUE)
## Simulate viral loads for the sample population
viral_loads <- simulate_viral_loads(infection_times, onset_times, times, pars)
length(infection_times)
source('~/Documents/GitHub/covid19-group-tests/code/viral_kinetics/simulation_functions.R', echo=TRUE)
source('~/Documents/GitHub/covid19-group-tests/code/viral_kinetics/simulate_data.R', echo=TRUE)
image(viral_loads_bin)
dev.off()
image(viral_loads_bin)
infection_times
length(infection_times)
hist(infection_times)
table(infection_times)
dim(Viral_loads)
dim(viral_loads)
viral_loads[,101]
sum(viral_loads[,101])
hist(viral_loads[,101])
sum(viral_loads_bin[,101])
viral_loads_bin[,101]
viral_loads_bin[,100]
imagE(viral_loads)
image(viral_loads)
dim(viral_loads)
dim(viral_loads_bin)
sum(viral_loads_bin[101,])
sum(viral_loads_bin[101,])/10000
epidemic_process$plot
source('~/Documents/GitHub/covid19-group-tests/code/viral_kinetics/simulate_data.R', echo=TRUE)
epidemic_procesess$\
epidemic_process$overall_prob_infection
source('~/Documents/GitHub/covid19-group-tests/code/viral_kinetics/simulate_data.R', echo=TRUE)
sum(viral_loads_bin[101,])
sum(viral_loads_bin[101,])/10000
image(viral_loads)
hist(viral_loads[,101])
wow <- viral_loads[,101]
hist(wow[wow > 0])
wow <- viral_loads[,100]
hist(wow[wow > 0])
library(tidyverse)
library(ggplot2)
## devtools::install_github("jameshay218/lazymcmc")
library(lazymcmc)
source("simulation_functions.R")
source("model_funcs.R")
## Entire popuation size (this is MA in 2018 from US Census Bureau)
population_n <- 6900000
## Sample size
n <- 10000
## Epidemic growth rate
growth_rate <- 0.1
## Duration of epidemic so far in days
times <- 0:200
## Viral kinetics pars
## Change wd to local path
parTab <- read.csv("pars/partab.csv",stringsAsFactors=FALSE)
chains <- load_mcmc_chains("~/Google Drive/nCoV/pool_samples/chains", parTab, FALSE, 1, burnin=200000,multi=TRUE)
chain <- as.data.frame(chains[[2]])
pars <- list(viral_peak_mean=mean(chain$viral_peak_mean), viral_peak_sd=mean(chain$viral_peak_sd),
wane_mean=mean(chain$wane_mean), wane_sd=mean(chain$wane_sd),
tp_last_day=7)
## Simulate the epidemic process
epidemic_process <- simulate_epidemic_process(population_n,0.1,times)
epidemic_process$plot
## Epidemic growth rate
growth_rate <- 0.05
## Duration of epidemic so far in days
times <- 0:200
## Viral kinetics pars
## Change wd to local path
parTab <- read.csv("pars/partab.csv",stringsAsFactors=FALSE)
chains <- load_mcmc_chains("~/Google Drive/nCoV/pool_samples/chains", parTab, FALSE, 1, burnin=200000,multi=TRUE)
chain <- as.data.frame(chains[[2]])
pars <- list(viral_peak_mean=mean(chain$viral_peak_mean), viral_peak_sd=mean(chain$viral_peak_sd),
wane_mean=mean(chain$wane_mean), wane_sd=mean(chain$wane_sd),
tp_last_day=7)
## Simulate the epidemic process
epidemic_process <- simulate_epidemic_process(population_n,0.1,times)
epidemic_process$plot
## Epidemic growth rate
growth_rate <- 0.1
## Duration of epidemic so far in days
times <- 0:100
## Viral kinetics pars
## Change wd to local path
parTab <- read.csv("pars/partab.csv",stringsAsFactors=FALSE)
chains <- load_mcmc_chains("~/Google Drive/nCoV/pool_samples/chains", parTab, FALSE, 1, burnin=200000,multi=TRUE)
chain <- as.data.frame(chains[[2]])
pars <- list(viral_peak_mean=mean(chain$viral_peak_mean), viral_peak_sd=mean(chain$viral_peak_sd),
wane_mean=mean(chain$wane_mean), wane_sd=mean(chain$wane_sd),
tp_last_day=7)
## Simulate the epidemic process
epidemic_process <- simulate_epidemic_process(population_n,0.1,times)
epidemic_process$plot
## Duration of epidemic so far in days
times <- 0:120
## Viral kinetics pars
## Change wd to local path
parTab <- read.csv("pars/partab.csv",stringsAsFactors=FALSE)
chains <- load_mcmc_chains("~/Google Drive/nCoV/pool_samples/chains", parTab, FALSE, 1, burnin=200000,multi=TRUE)
chain <- as.data.frame(chains[[2]])
pars <- list(viral_peak_mean=mean(chain$viral_peak_mean), viral_peak_sd=mean(chain$viral_peak_sd),
wane_mean=mean(chain$wane_mean), wane_sd=mean(chain$wane_sd),
tp_last_day=7)
## Simulate the epidemic process
epidemic_process <- simulate_epidemic_process(population_n,0.1,times)
epidemic_process$plot
## Simulate infection times
infection_times <- simulate_infection_times(n, epidemic_process$overall_prob_infection, epidemic_process$incidence)
## Simulate symptom onset times using default incubation period distribution
onset_times <- simulate_symptom_onsets(infection_times)
## Simulate viral loads for the sample population
viral_loads <- simulate_viral_loads(infection_times, onset_times, times, pars)
## Have a look to see the window of detection for each simulated individual
viral_loads_bin <- apply(viral_loads, 1, function(x) x >= 2)
image(viral_loads_bin)
hist(viral_load_bin[101,])
hist(viral_load[,101])
hist(viral_loads[,101])
hist(viral_loads[,115])
wow <- viral_loads[,115]
hist(wow[wow > 0])
wow <- viral_loads[,120]
hist(wow[wow > 0])
viral_loads
viral_loads[which(infection_times > 0),]
rowMeans(viral_loads[which(infection_times > 0),])
hist(rowMeans(viral_loads[which(infection_times > 0),]))
tmp <- viral_loads[which(infection_times > 0),]
tmp
apply(tmp, 1, function(x) mean(x[x > 0]))
hist(apply(tmp, 1, function(x) mean(x[x > 0])))
viral_loads <- simulate_viral_loads(infection_times, onset_times, times, pars)
tmp <- viral_loads[which(infection_times > 0),]
hist(apply(tmp, 1, function(x) mean(x[x > 0])))
viral_loads <- simulate_viral_loads(infection_times, onset_times, times, pars)
tmp <- viral_loads[which(infection_times > 0),]
hist(apply(tmp, 1, function(x) mean(x[x > 0])))
## Entire popuation size (this is MA in 2018 from US Census Bureau)
population_n <- 6900000
## Sample size
n <- 10000
## Epidemic growth rate
growth_rate <- 0.1
## Duration of epidemic so far in days
times <- 0:120
## Viral kinetics pars
## Change wd to local path
parTab <- read.csv("pars/partab.csv",stringsAsFactors=FALSE)
chains <- load_mcmc_chains("~/Google Drive/nCoV/pool_samples/chains", parTab, FALSE, 1, burnin=200000,multi=TRUE)
chain <- as.data.frame(chains[[2]])
pars <- list(viral_peak_mean=mean(chain$viral_peak_mean), viral_peak_sd=mean(chain$viral_peak_sd),
wane_mean=mean(chain$wane_mean), wane_sd=mean(chain$wane_sd),
tp_last_day=7)
## Simulate the epidemic process
epidemic_process <- simulate_epidemic_process(population_n,0.1,times)
epidemic_process$plot
## Simulate infection times
infection_times <- simulate_infection_times(n, epidemic_process$overall_prob_infection, epidemic_process$incidence)
## Simulate symptom onset times using default incubation period distribution
onset_times <- simulate_symptom_onsets(infection_times)
## Simulate viral loads for the sample population
viral_loads <- simulate_viral_loads(infection_times, onset_times, times, pars)
tmp <- viral_loads[which(infection_times > 0),]
hist(apply(tmp, 1, function(x) mean(x[x > 0])))
## Entire popuation size (this is MA in 2018 from US Census Bureau)
population_n <- 6900000
## Sample size
n <- 10000
## Epidemic growth rate
growth_rate <- 0.1
## Duration of epidemic so far in days
times <- 0:120
## Viral kinetics pars
## Change wd to local path
parTab <- read.csv("pars/partab.csv",stringsAsFactors=FALSE)
chains <- load_mcmc_chains("~/Google Drive/nCoV/pool_samples/chains", parTab, FALSE, 1, burnin=200000,multi=TRUE)
chain <- as.data.frame(chains[[2]])
pars <- list(viral_peak_mean=mean(chain$viral_peak_mean), viral_peak_sd=mean(chain$viral_peak_sd),
wane_mean=mean(chain$wane_mean), wane_sd=mean(chain$wane_sd),
tp_last_day=7)
## Simulate the epidemic process
epidemic_process <- simulate_epidemic_process(population_n,0.1,times)
epidemic_process$plot
## Simulate infection times
infection_times <- simulate_infection_times(n, epidemic_process$overall_prob_infection, epidemic_process$incidence)
## Simulate symptom onset times using default incubation period distribution
onset_times <- simulate_symptom_onsets(infection_times)
## Simulate viral loads for the sample population
viral_loads <- simulate_viral_loads(infection_times, onset_times, times, pars)
tmp <- viral_loads[which(infection_times > 0),]
hist(apply(tmp, 1, function(x) mean(x[x > 0])))
epidemic_process$incidence
incidence <- rep(1, 120)
incidence
incidence <- rep(1, 120)/120
infection_times <- simulate_infection_times(n, 0.05,
incidence)
## Simulate symptom onset times using default incubation period distribution
onset_times <- simulate_symptom_onsets(infection_times)
## Simulate viral loads for the sample population
viral_loads <- simulate_viral_loads(infection_times, onset_times, times, pars)
tmp <- viral_loads[which(infection_times > 0),]
hist(apply(tmp, 1, function(x) mean(x[x > 0])))
## Have a look to see the window of detection for each simulated individual
viral_loads_bin <- apply(viral_loads, 1, function(x) x >= 2)
image(viral_loads_bin)
hist(viral_loads[101,])
hist(viral_loads[,101])
hist(viral_loads[viral_loads[,101] > 0, 101])
i <- 101
hist(viral_loads[viral_loads[,i] > 0, i])
i <- 115
hist(viral_loads[viral_loads[,i] > 0, i])
i <- 129
i <- 120
hist(viral_loads[viral_loads[,i] > 0, i])
i <- 90
hist(viral_loads[viral_loads[,i] > 0, i])
i <- 80
hist(viral_loads[viral_loads[,i] > 0, i])
par(mfrow=c(3,4))
wow <- seq(1,120,by=10)
for(i in seq_along(wow)) hist(viral_loads[viral_loads[,wow[i]] > 0, wow[i]])
wow <- seq(60,120,by=10)
for(i in seq_along(wow)) hist(viral_loads[viral_loads[,wow[i]] > 0, wow[i]])
rowSums(viral_loads_bin)
rowSums(viral_loads_bin)/n
1/120
1/121
plot(rowSums(viral_loads_bin)/n)
par(mfrow=c(1,1))
source('~/Documents/GitHub/covid19-group-tests/code/viral_kinetics/simulate_data.R', echo=TRUE)
rowSums(viral_loads_bin)
rowSums(viral_loads_bin)/10000
wow <- seq(60,120,by=10)
for(i in seq_along(wow)){
hist(viral_loads[viral_loads[,wow[i]] > 0, wow[i]])
}
par(mfrow=c(3,2))
wow <- seq(60,120,by=10)
for(i in seq_along(wow)){
hist(viral_loads[viral_loads[,wow[i]] > 0, wow[i]])
}
seq_along(wow)
wow <- seq(60,120,by=10)
for(i in seq_along(wow)){
hist(viral_loads[viral_loads[,wow[i]] > 0, wow[i]])
}
seq_along(wow)
par(mfrow=c(3,2))
wow <- seq(60,120,by=10)
for(i in seq_along(wow)){
hist(viral_loads[viral_loads[,wow[i]] > 0, wow[i]])
}
hist(viral_loads[viral_loads[,wow[i]] > 0, wow[i]])
hist(viral_loads[viral_loads[,wow[i]] > 0, wow[i]])
hist(viral_loads[viral_loads[,wow[i]] > 0, wow[i]])
par(mfrow=c(3,2))
wow <- seq(60,120,by=10)
for(i in seq_along(wow)){
print(wow[i])
hist(viral_loads[viral_loads[,wow[i]] > 0, wow[i]])
}
hist(viral_loads[viral_loads[,wow[1]] > 0, wow[1]])
hist(viral_loads[viral_loads[,wow[2]] > 0, wow[2]])
hist(viral_loads[viral_loads[,wow[3]] > 0, wow[3]])
hist(viral_loads[viral_loads[,wow[4]] > 0, wow[4]])
hist(viral_loads[viral_loads[,wow[5]] > 0, wow[5]])
hist(viral_loads[viral_loads[,wow[1]] > 0, wow[1]])
hist(viral_loads[viral_loads[,wow[2]] > 0, wow[2]])
hist(viral_loads[viral_loads[,wow[3]] > 0, wow[3]])
hist(viral_loads[viral_loads[,wow[4]] > 0, wow[4]])
hist(viral_loads[viral_loads[,wow[5]] > 0, wow[5]])
hist(viral_loads[viral_loads[,wow[6]] > 0, wow[6]])
hist(viral_loads[viral_loads[,wow[1]] > 0, wow[1]],xlim=c(0,10),breaks=11)
hist(viral_loads[viral_loads[,wow[1]] > 0, wow[1]],xlim=c(0,10),breaks=10)
par(mfrow=c(3,2))
wow <- seq(60,120,by=10)
hist(viral_loads[viral_loads[,wow[1]] > 0, wow[1]],xlim=c(0,10),breaks=10)
hist(viral_loads[viral_loads[,wow[2]] > 0, wow[2]],xlim=c(0,10),breaks=10)
hist(viral_loads[viral_loads[,wow[3]] > 0, wow[3]],xlim=c(0,10),breaks=10)
hist(viral_loads[viral_loads[,wow[4]] > 0, wow[4]],xlim=c(0,10),breaks=10)
hist(viral_loads[viral_loads[,wow[5]] > 0, wow[5]],xlim=c(0,10),breaks=10)
hist(viral_loads[viral_loads[,wow[6]] > 0, wow[6]],xlim=c(0,10),breaks=10)
tmp <- viral_loads[which(infection_times > 0),]
hist(apply(tmp, 1, function(x) mean(x[x > 0])))
## Simulate viral loads for the sample population
viral_loads <- simulate_viral_loads(infection_times, onset_times, times, pars)
tmp <- viral_loads[which(infection_times > 0),]
hist(apply(tmp, 1, function(x) mean(x[x > 0])))
par(mfrow=c(3,2))
wow <- seq(60,120,by=10)
hist(viral_loads[viral_loads[,wow[1]] > 0, wow[1]],xlim=c(0,10),breaks=10)
hist(viral_loads[viral_loads[,wow[2]] > 0, wow[2]],xlim=c(0,10),breaks=10)
hist(viral_loads[viral_loads[,wow[3]] > 0, wow[3]],xlim=c(0,10),breaks=10)
hist(viral_loads[viral_loads[,wow[4]] > 0, wow[4]],xlim=c(0,10),breaks=10)
hist(viral_loads[viral_loads[,wow[5]] > 0, wow[5]],xlim=c(0,10),breaks=10)
hist(viral_loads[viral_loads[,wow[6]] > 0, wow[6]],xlim=c(0,10),breaks=10)
par(mfrow=c(1,1))
